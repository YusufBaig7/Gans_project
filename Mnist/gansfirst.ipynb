{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train_images,train_labels),(test_images,test_labels) = tf.keras.datasets.mnist.load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(train_images[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = train_images/255\ntest_images = test_images/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BUFFER_SIZE = train_images.shape[0]\nBATCH_SIZE = 100\ntrain_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_discriminator_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(7,(3,3), padding ='same', input_shape = (28,28,1)),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.LeakyReLU(),\n        tf.keras.layers.Dense(50, activation = 'relu'),\n        tf.keras.layers.Dense(1)\n    ])    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_discriminator = make_discriminator_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_discriminator(np.random.rand(1, 28, 28, 1).astype('float32'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator_optimizer = tf.optimizers.Adam(1e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_discriminator_loss(real_predictions, fake_predictions):\n    real_predictions = tf.sigmoid(real_predictions)\n    fake_predictions = tf.sigmoid(fake_predictions)\n    real_loss = tf.losses.binary_crossentropy(tf.ones_like(real_predictions), real_predictions)\n    fake_loss = tf.losses.binary_crossentropy(tf.zeros_like(fake_predictions), fake_predictions)\n    return real_loss + fake_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_generator_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Dense(7*7*256, input_shape = (100,)),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Reshape((7, 7, 256)),\n        tf.keras.layers.Conv2DTranspose(128, (3, 3), padding = 'same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Conv2DTranspose(64, (3, 3), strides = (2, 2), padding = 'same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Conv2DTranspose(1, (3, 3), strides = (2, 2), padding = 'same')\n    ])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator = make_generator_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator_optimizer = tf.optimizers.Adam(1e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_generator_loss(fake_predictions):\n    fake_predictions = tf.sigmoid(fake_predictions)\n    fake_loss = tf.losses.binary_crossentropy(tf.ones_like(fake_predictions), fake_predictions)\n    return fake_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(dataset, epochs):\n    for _ in range(epochs):\n        for images in dataset:\n            images = tf.cast(images, tf.dtypes.float32)\n            train_step(images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_step(images):\n    fake_image_noise = np.random.randn(BATCH_SIZE, 100).astype('float32')\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator(fake_image_noise)\n        real_output = model_discriminator(images)\n        fake_output = model_discriminator(generated_images)\n    \n        gen_loss = get_generator_loss(fake_output)\n        disc_loss = get_discriminator_loss(real_output, fake_output)\n    \n        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n        gradients_of_discriminator = disc_tape.gradient(disc_loss, model_discriminator.trainable_variables)\n    \n        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, model_discriminator.trainable_variables))\n    \n        print('Generator loss is:', np.mean(gen_loss))\n        print('Discriminator loss is:', np.mean(disc_loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(train_dataset, 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(tf.reshape(generator(np.random.randn(1,100)),(28,28)),cmap = \"gray\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}